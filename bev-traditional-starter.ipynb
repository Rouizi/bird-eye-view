{"metadata":{"colab":{"private_outputs":true,"provenance":[],"collapsed_sections":["YbzKudm36sg8"]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7011435,"sourceType":"datasetVersion","datasetId":4029663}],"dockerImageVersionId":30558,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Geometric Approaches: Inverse Perspective Mapping","metadata":{"id":"y-P9PyG-6qCR"}},{"cell_type":"markdown","source":"**Imports**","metadata":{"id":"_paO6l88C366"}},{"cell_type":"code","source":"import cv2\nimport numpy as np\nimport matplotlib.pyplot as plt","metadata":{"id":"5GhVDrHsCbyS","execution":{"iopub.status.busy":"2023-11-20T15:22:52.047133Z","iopub.execute_input":"2023-11-20T15:22:52.047547Z","iopub.status.idle":"2023-11-20T15:22:52.098867Z","shell.execute_reply.started":"2023-11-20T15:22:52.047513Z","shell.execute_reply":"2023-11-20T15:22:52.097334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Load a Rectified Image from the KITTI Dataset**","metadata":{"id":"LHFmlzfQC5k_"}},{"cell_type":"code","source":"image = #TODO: Load the Stuttgart Image from the Geometric > Geometric > Folder file\n\nplt.imshow(image)\nplt.show())","metadata":{"id":"b04-uAmjCfmZ","execution":{"iopub.status.busy":"2023-11-20T15:24:10.903006Z","iopub.execute_input":"2023-11-20T15:24:10.903407Z","iopub.status.idle":"2023-11-20T15:24:11.708478Z","shell.execute_reply.started":"2023-11-20T15:24:10.903373Z","shell.execute_reply":"2023-11-20T15:24:11.707638Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"h, w, d = image.shape\nw, h, d","metadata":{"id":"5ZG1jdt7bdb9","execution":{"iopub.status.busy":"2023-11-20T15:24:16.534762Z","iopub.execute_input":"2023-11-20T15:24:16.535223Z","iopub.status.idle":"2023-11-20T15:24:16.543048Z","shell.execute_reply.started":"2023-11-20T15:24:16.535187Z","shell.execute_reply":"2023-11-20T15:24:16.541683Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **IPM with 4 Points**","metadata":{"id":"b6nQC5UUGVDu"}},{"cell_type":"markdown","source":"**Define 4 Points of Transformation**","metadata":{"id":"SH0JR3WCCyoY"}},{"cell_type":"code","source":"img = np.copy(image)\nsrc_1 = #TODO: Define the top left point\nsrc_2 = #TODO: Define the bottom left point\nsrc_3 = #TODO: Defien the top right point\nsrc_4 = #TODO: Define the bottom right point\n\ncv2.circle(img, src_1, radius=15, color=(0,0,205),thickness=-1)\ncv2.circle(img, src_2, radius=15, color=(0,0,205),thickness=-1)\ncv2.circle(img, src_3, radius=15, color=(0,0,205),thickness=-1)\ncv2.circle(img, src_4, radius=15, color=(0,0,205),thickness=-1)\nplt.imshow(img)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-20T15:43:07.760745Z","iopub.execute_input":"2023-11-20T15:43:07.761181Z","iopub.status.idle":"2023-11-20T15:43:08.419347Z","shell.execute_reply.started":"2023-11-20T15:43:07.761146Z","shell.execute_reply":"2023-11-20T15:43:08.418507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img2 = np.copy(img)\n\ndst_1 = #TODO: Define the top left point\ndst_2 = #TODO: Define the bottom left point\ndst_3 = #TODO: Defien the top right point\ndst_4 = #TODO: Define the bottom right point\n\ncv2.rectangle(img2, dst_1, dst_4, (205,0,0),4)\n\nplt.imshow(img2)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-20T15:43:08.420931Z","iopub.execute_input":"2023-11-20T15:43:08.421429Z","iopub.status.idle":"2023-11-20T15:43:09.086429Z","shell.execute_reply.started":"2023-11-20T15:43:08.421399Z","shell.execute_reply":"2023-11-20T15:43:09.083886Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Apply the Transformation**","metadata":{"id":"DdlV8uhSC69k"}},{"cell_type":"code","source":"src_points = np.array([src_1, src_2, src_3, src_4],dtype=np.float32)  # Original Region of Interest\ndst_points = np.array([dst_1, dst_2, dst_3, dst_4],dtype=np.float32)   # Projected Rectangle","metadata":{"id":"UomsFAzZC1SY","execution":{"iopub.status.busy":"2023-11-20T15:43:11.048341Z","iopub.execute_input":"2023-11-20T15:43:11.048971Z","iopub.status.idle":"2023-11-20T15:43:11.055617Z","shell.execute_reply.started":"2023-11-20T15:43:11.048933Z","shell.execute_reply":"2023-11-20T15:43:11.054306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.set_printoptions(precision=4, suppress=True)\nM = #TODO: Call the perspective transform function from openCV\nprint(M)","metadata":{"id":"heeC_wZklvTU","execution":{"iopub.status.busy":"2023-11-20T15:43:11.471908Z","iopub.execute_input":"2023-11-20T15:43:11.472621Z","iopub.status.idle":"2023-11-20T15:43:11.478484Z","shell.execute_reply.started":"2023-11-20T15:43:11.472584Z","shell.execute_reply":"2023-11-20T15:43:11.477579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"warped_img = #TODO: Call the warp perspective function from openCV\n\nplt.imshow(warped_img)\nplt.show()","metadata":{"id":"6Jxl7HVhC-Ik","execution":{"iopub.status.busy":"2023-11-20T15:47:02.41614Z","iopub.execute_input":"2023-11-20T15:47:02.416839Z","iopub.status.idle":"2023-11-20T15:47:03.053918Z","shell.execute_reply.started":"2023-11-20T15:47:02.416803Z","shell.execute_reply":"2023-11-20T15:47:03.052819Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**This is done completely manually. A better alternative is to use the camera intrinsic and extrinsic calibration parameters**","metadata":{"id":"-ql2hIeQFOZT"}},{"cell_type":"markdown","source":"## IPM with Parameters\nLater in the course, you're going to apply IPM inside a Spatial Transformer Network. That part will be abstracted later on, but we WILL work on it right now.","metadata":{}},{"cell_type":"markdown","source":"First, we load a new image","metadata":{}},{"cell_type":"code","source":"filename= #TODO: Load a front image from the Geometric>Geometric>Front Dataset (ideally with no obstacles in front, like t_0_0_0001000.png)\n\nimage = cv2.cvtColor(cv2.imread(filename), cv2.COLOR_BGR2RGB)\nplt.imshow(image)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-20T15:48:47.143617Z","iopub.execute_input":"2023-11-20T15:48:47.144897Z","iopub.status.idle":"2023-11-20T15:48:47.529835Z","shell.execute_reply.started":"2023-11-20T15:48:47.144844Z","shell.execute_reply":"2023-11-20T15:48:47.528249Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Next, we load the camera parameters**.\nTo do this, we'll need:\n* The intrinsic calibation matrix K\n* The position of the camera\n* The Yaw, Pitch, and Roll","metadata":{}},{"cell_type":"code","source":"import yaml\nwith open(\"/kaggle/input/front-test/geometric/geometric/front/front.yaml\") as stream:\n    camConfig = yaml.safe_load(stream)\n    \nprint(camConfig)","metadata":{"execution":{"iopub.status.busy":"2023-11-20T15:49:35.502117Z","iopub.execute_input":"2023-11-20T15:49:35.502665Z","iopub.status.idle":"2023-11-20T15:49:35.549733Z","shell.execute_reply.started":"2023-11-20T15:49:35.502605Z","shell.execute_reply":"2023-11-20T15:49:35.548519Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# camera calibration matrix K\nfx= #TODO: Pick from the config file\nfy= #TODO: Pick from the config file\npx= #TODO: Pick from the config file\npy= #TODO: Pick from the config file\n\n# rotation matrix R (in deg)\nyaw= #TODO: Pick from the config file\npitch= #TODO: Pick from the config file\nroll= #TODO: Pick from the config file\n\n# vehicle coords of camera origin\nXCam= #TODO: Pick from the config file\nYCam=#TODO: Pick from the config file\nZCam= #TODO: Pick from the config file","metadata":{"execution":{"iopub.status.busy":"2023-11-20T15:50:48.875134Z","iopub.execute_input":"2023-11-20T15:50:48.875569Z","iopub.status.idle":"2023-11-20T15:50:48.882198Z","shell.execute_reply.started":"2023-11-20T15:50:48.875533Z","shell.execute_reply":"2023-11-20T15:50:48.881113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"K = np.zeros([3, 3])\nR = np.zeros([3, 3])\nt = np.zeros([3, 1])\nP = np.zeros([3, 4])","metadata":{"execution":{"iopub.status.busy":"2023-11-20T15:50:55.255238Z","iopub.execute_input":"2023-11-20T15:50:55.255951Z","iopub.status.idle":"2023-11-20T15:50:55.261607Z","shell.execute_reply.started":"2023-11-20T15:50:55.25591Z","shell.execute_reply":"2023-11-20T15:50:55.260532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Set K\n\nK #TODO: Fill K with matrices from the config file\n","metadata":{"execution":{"iopub.status.busy":"2023-11-20T15:50:56.015763Z","iopub.execute_input":"2023-11-20T15:50:56.016189Z","iopub.status.idle":"2023-11-20T15:50:56.022185Z","shell.execute_reply.started":"2023-11-20T15:50:56.016153Z","shell.execute_reply":"2023-11-20T15:50:56.020861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y = np.deg2rad(yaw) \np = np.deg2rad(pitch)\nr = np.deg2rad(roll)\n\n## Set R\nRz = #TODO: Implement the matrix for Rz\nRy = #TODO: Implement the matrix for Ry\nRx = #TODO: Implement the matrix for Rx\n\n#Rs = np.array([[0.0, -1.0, 0.0], [0.0, 0.0, -1.0], [1.0, 0.0, 0.0]]) # switch axes (x = -y, y = -z, z = x)\nRs = np.array([[0.0, 1.0, 0.0], [0.0, 0.0, -1.0], [1.0, 0.0, 0.0]]) # switch axes (x = -y, y = -z, z = x) #Additional R matrix\n\nR = #TODO: R = Rs*(Rz*(Ry*Rx))","metadata":{"execution":{"iopub.status.busy":"2023-11-20T15:50:57.751331Z","iopub.execute_input":"2023-11-20T15:50:57.75182Z","iopub.status.idle":"2023-11-20T15:50:57.762097Z","shell.execute_reply.started":"2023-11-20T15:50:57.751784Z","shell.execute_reply":"2023-11-20T15:50:57.760839Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Set T\nX = #Define X, an array with X, Y, Z cam\nt = #TODO: -R*X","metadata":{"execution":{"iopub.status.busy":"2023-11-20T15:50:59.93881Z","iopub.execute_input":"2023-11-20T15:50:59.939209Z","iopub.status.idle":"2023-11-20T15:50:59.943747Z","shell.execute_reply.started":"2023-11-20T15:50:59.939174Z","shell.execute_reply":"2023-11-20T15:50:59.942948Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Update P\nRt = np.zeros([3, 4])\nRt[0:3, 0:3] = R\nRt[0:3, 3] = t\nP = #TODO: Define P","metadata":{"execution":{"iopub.status.busy":"2023-11-20T15:51:01.05955Z","iopub.execute_input":"2023-11-20T15:51:01.059948Z","iopub.status.idle":"2023-11-20T15:51:01.069123Z","shell.execute_reply.started":"2023-11-20T15:51:01.059917Z","shell.execute_reply":"2023-11-20T15:51:01.067917Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(P)","metadata":{"execution":{"iopub.status.busy":"2023-11-20T15:51:02.140411Z","iopub.execute_input":"2023-11-20T15:51:02.141072Z","iopub.status.idle":"2023-11-20T15:51:02.147623Z","shell.execute_reply.started":"2023-11-20T15:51:02.14103Z","shell.execute_reply":"2023-11-20T15:51:02.146519Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Transform**","metadata":{}},{"cell_type":"code","source":"import sys\nsys.path.append(\"/kaggle/input/front-test/geometric/geometric/\")\nfrom utils import Plane, meshgrid, bilinear_sampler, perspective\n\nTARGET_W, TARGET_H = #TODO: Define the size of a plane\nplane = Plane(0, -25, 0, 0, 0, 0, TARGET_H, TARGET_W, 0.1)\n\npixel_coords = #TODO: Call the perspective function\nimg_bev = #TODO: Upsample the points\nplt.imshow(img_bev.astype(int))\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-20T15:52:07.018165Z","iopub.execute_input":"2023-11-20T15:52:07.018602Z","iopub.status.idle":"2023-11-20T15:52:07.496362Z","shell.execute_reply.started":"2023-11-20T15:52:07.01856Z","shell.execute_reply":"2023-11-20T15:52:07.495092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Try on other images? \nThe other folders have their own camera parameters, and images.","metadata":{}},{"cell_type":"code","source":"import yaml\nimport os\n\nfilename= '/kaggle/input/front-test/geometric/geometric/rear/rear.png'\nimage = cv2.cvtColor(cv2.imread(filename), cv2.COLOR_BGR2RGB)\nplt.imshow(image)\nplt.show()\n\nwith open(\"/kaggle/input/front-test/geometric/geometric/rear/rear.yaml\") as stream:\n    camConfig = yaml.safe_load(stream)\n    \nprint(camConfig)","metadata":{"execution":{"iopub.status.busy":"2023-11-20T15:53:34.682102Z","iopub.execute_input":"2023-11-20T15:53:34.682506Z","iopub.status.idle":"2023-11-20T15:53:35.036326Z","shell.execute_reply.started":"2023-11-20T15:53:34.682473Z","shell.execute_reply":"2023-11-20T15:53:35.035Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_parameters(camConfig):\n    K = np.zeros([3, 3])\n    R = np.zeros([3, 3])\n    t = np.zeros([3, 1])\n    P = np.zeros([3, 4])\n    K[0, 0] = camConfig['fx']\n    K[1, 1] = camConfig['fy']\n    K[0, 2] = camConfig['px']\n    K[1, 2] = camConfig['py']\n    K[2, 2] = 1.0\n    y = np.deg2rad(camConfig['yaw']) \n    p = np.deg2rad(camConfig['pitch'])\n    r = np.deg2rad(camConfig['roll'])\n\n    ## Set R\n    Rz = np.array([[np.cos(-y), -np.sin(-y), 0.0], [np.sin(-y), np.cos(-y), 0.0], [0.0, 0.0, 1.0]])\n    Ry = np.array([[np.cos(-p), 0.0, np.sin(-p)], [0.0, 1.0, 0.0], [-np.sin(-p), 0.0, np.cos(-p)]])\n    Rx = np.array([[1.0, 0.0, 0.0], [0.0, np.cos(-r), -np.sin(-r)], [0.0, np.sin(-r), np.cos(-r)]])\n    #Rs = np.array([[0.0, -1.0, 0.0], [0.0, 0.0, -1.0], [1.0, 0.0, 0.0]]) # switch axes (x = -y, y = -z, z = x)\n    Rs = np.array([[0.0, 1.0, 0.0], [0.0, 0.0, -1.0], [1.0, 0.0, 0.0]]) # switch axes (x = -y, y = -z, z = x)\n    R = Rs.dot(Rz.dot(Ry.dot(Rx)))\n        \n    ## Set T\n    X = np.array([camConfig['XCam'], camConfig['YCam'], camConfig['ZCam']])\n    t = -R.dot(X)\n    \n    Rt = np.zeros([3, 4])\n    Rt[0:3, 0:3] = R\n    Rt[0:3, 3] = t\n    P = K.dot(Rt)\n    return P\n\nP = get_parameters(camConfig)","metadata":{"execution":{"iopub.status.busy":"2023-11-20T15:53:44.255318Z","iopub.execute_input":"2023-11-20T15:53:44.256089Z","iopub.status.idle":"2023-11-20T15:53:44.26963Z","shell.execute_reply.started":"2023-11-20T15:53:44.256049Z","shell.execute_reply":"2023-11-20T15:53:44.268789Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Repeat the Projection Code**","metadata":{}},{"cell_type":"code","source":"TARGET_W, TARGET_H = 500, 500\nplane = Plane(-50, -25, -25, 0, 0, 0, TARGET_H, TARGET_W, 0.1)\n\npixel_coords = perspective(plane.xyz, P, TARGET_H, TARGET_W)\nimg_bev = bilinear_sampler(np.copy(image), pixel_coords)\nplt.imshow(img_bev.astype(int))\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-20T15:53:45.674849Z","iopub.execute_input":"2023-11-20T15:53:45.675289Z","iopub.status.idle":"2023-11-20T15:53:46.102823Z","shell.execute_reply.started":"2023-11-20T15:53:45.675252Z","shell.execute_reply":"2023-11-20T15:53:46.101563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Inverse Projections with Depth**","metadata":{"id":"rkus765ogtZz"}},{"cell_type":"markdown","source":"### Original Code","metadata":{}},{"cell_type":"code","source":"import imageio\nimageio.plugins.freeimage.download()\n\ndepth = #TODO: Load the Depth.EXR image from Depth>Depth\nimage = #TODO: Load the RGB Image from Depth > Depth\n\nplt.imshow(depth, cmap=\"inferno\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-20T15:54:51.386904Z","iopub.execute_input":"2023-11-20T15:54:51.387325Z","iopub.status.idle":"2023-11-20T15:54:51.807799Z","shell.execute_reply.started":"2023-11-20T15:54:51.38729Z","shell.execute_reply":"2023-11-20T15:54:51.806695Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(depth)","metadata":{"execution":{"iopub.status.busy":"2023-11-20T15:54:56.677473Z","iopub.execute_input":"2023-11-20T15:54:56.678522Z","iopub.status.idle":"2023-11-20T15:54:56.685276Z","shell.execute_reply.started":"2023-11-20T15:54:56.678485Z","shell.execute_reply":"2023-11-20T15:54:56.683791Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(image.shape)\nprint(depth.shape)\nheight, width = depth.shape[:2]","metadata":{"execution":{"iopub.status.busy":"2023-11-20T15:54:57.420557Z","iopub.execute_input":"2023-11-20T15:54:57.420973Z","iopub.status.idle":"2023-11-20T15:54:57.426755Z","shell.execute_reply.started":"2023-11-20T15:54:57.420938Z","shell.execute_reply":"2023-11-20T15:54:57.425614Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def intrinsic_from_fov(height, width, fov=90):\n    \"\"\"\n    Basic Pinhole Camera Model\n    intrinsic params from fov and sensor width and height in pixels\n    Returns:\n        K:      [4, 4]\n    \"\"\"     \n    px, py = (width / 2, height / 2)\n    hfov = fov / 360. * 2. * np.pi\n    fx = width / (2. * np.tan(hfov / 2.))\n\n    vfov = 2. * np.arctan(np.tan(hfov / 2) * height / width)\n    fy = height / (2. * np.tan(vfov / 2.))\n\n    return np.array([[fx, 0, px, 0.],\n                     [0, fy, py, 0.],\n                     [0, 0, 1., 0.],\n                     [0., 0., 0., 1.]])\n\nintrinsic = intrinsic_from_fov(height, width)","metadata":{"execution":{"iopub.status.busy":"2023-11-20T15:55:35.610206Z","iopub.execute_input":"2023-11-20T15:55:35.61138Z","iopub.status.idle":"2023-11-20T15:55:35.620286Z","shell.execute_reply.started":"2023-11-20T15:55:35.611338Z","shell.execute_reply":"2023-11-20T15:55:35.618861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cam_coords = np.zeros((height * width, 3))\n\nu0 = intrinsic[0, 2]\nv0 = intrinsic[1, 2]\nfx = intrinsic[0, 0]\nfy = intrinsic[1, 1]\ni = 0\n\n# Loop through each pixel in the image\nfor v in range(height):\n    for u in range(width):\n        x = # TODO: Define X\n        y = # TODO: Define Y\n        z = # TODO: Define Z\n        cam_coords[i] = (x, y, z)\n        i += 1\ncam_coords = cam_coords.T\n","metadata":{"execution":{"iopub.status.busy":"2023-11-20T15:55:42.654259Z","iopub.execute_input":"2023-11-20T15:55:42.654752Z","iopub.status.idle":"2023-11-20T15:55:45.929348Z","shell.execute_reply.started":"2023-11-20T15:55:42.65466Z","shell.execute_reply":"2023-11-20T15:55:45.928147Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def project_depthmap(cam_points,rgb, cam_pos = -1.2):\n    max_longitudinal = #TODO: Define a Max Distance\n    window_x = #TODO: Define a Side Window\n    window_y = #TODO: Define a Range Window\n\n    x, y, z = cam_points\n    # flip the y-axis to positive upwards\n    y = - y\n\n    # We sample points for points less than 70m ahead and above ground\n    # Camera is mounted 1m above on an ego vehicle\n    ind = np.where((z < max_longitudinal) & (y > cam_pos))\n    #ind = np.where(z < max_longitudinal)\n    bird_eye = cam_points[:3, ind]\n\n    # Color by pixels or radial distance\n    dists = np.sqrt(np.sum(bird_eye[0:2:2, :] ** 2, axis=0))\n    axes_limit = 10\n    colors = np.minimum(1, dists / axes_limit / np.sqrt(2))\n    fig, (ax0, ax1) = plt.subplots(1, 2, figsize=(24, 12))\n    ax0.imshow(rgb)\n    ax0.set_title(\"Original Image\")\n    ax0.axis(\"off\")\n    ax1.scatter(bird_eye[0, :], bird_eye[2, :], c=colors, s=0.1)\n    ax1.set_xlim(window_x)\n    ax1.set_ylim(window_y)\n    ax1.set_title('Bird Eye View')\n    plt.axis('off')\n\n    plt.gca().set_aspect('equal')\n    plt.show()\n\nproject_depthmap(cam_coords, image)","metadata":{"execution":{"iopub.status.busy":"2023-11-20T16:01:25.179247Z","iopub.execute_input":"2023-11-20T16:01:25.179665Z","iopub.status.idle":"2023-11-20T16:01:31.743129Z","shell.execute_reply.started":"2023-11-20T16:01:25.179632Z","shell.execute_reply":"2023-11-20T16:01:31.741725Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### KITTI Challenge","metadata":{}},{"cell_type":"code","source":"image = cv2.cvtColor(cv2.imread('/kaggle/input/front-test/depth/depth/KITTI/000009.png'), cv2.COLOR_BGR2RGB)\nplt.imshow(image)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-20T16:08:43.262813Z","iopub.execute_input":"2023-11-20T16:08:43.263218Z","iopub.status.idle":"2023-11-20T16:08:43.63186Z","shell.execute_reply.started":"2023-11-20T16:08:43.263186Z","shell.execute_reply":"2023-11-20T16:08:43.630749Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"depth = np.load(\"/kaggle/input/front-test/depth/depth/KITTI/depth_map_monodepth.npy\")\nprint(depth.shape)\nplt.imshow(depth, cmap=\"magma\")","metadata":{"execution":{"iopub.status.busy":"2023-11-20T16:08:43.633531Z","iopub.execute_input":"2023-11-20T16:08:43.634112Z","iopub.status.idle":"2023-11-20T16:08:43.979365Z","shell.execute_reply.started":"2023-11-20T16:08:43.634074Z","shell.execute_reply":"2023-11-20T16:08:43.978246Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(image.shape)\nprint(depth.shape)\nprint((depth))","metadata":{"execution":{"iopub.status.busy":"2023-11-20T16:08:06.474461Z","iopub.execute_input":"2023-11-20T16:08:06.474894Z","iopub.status.idle":"2023-11-20T16:08:06.483068Z","shell.execute_reply.started":"2023-11-20T16:08:06.47486Z","shell.execute_reply":"2023-11-20T16:08:06.481845Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def disp_to_depth(disp, min_depth, max_depth): \n    '''\n    Convert network's sigmoid output into depth prediction \n    The formula for this conversion is given in the 'additional considerations' \n    section of the paper. \n    ''' \n    min_disp = 1 / max_depth \n    max_disp = 1 / min_depth \n    scaled_disp = min_disp + (max_disp - min_disp) * disp \n    depth = 1 / scaled_disp \n    return scaled_disp, depth\n\nscaled_disp, depth = disp_to_depth(depth, 1e-3, 80)","metadata":{"execution":{"iopub.status.busy":"2023-11-20T16:04:29.973881Z","iopub.execute_input":"2023-11-20T16:04:29.974315Z","iopub.status.idle":"2023-11-20T16:04:29.982531Z","shell.execute_reply.started":"2023-11-20T16:04:29.974281Z","shell.execute_reply":"2023-11-20T16:04:29.981546Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(np.max(scaled_disp))","metadata":{"execution":{"iopub.status.busy":"2023-11-20T16:04:39.302712Z","iopub.execute_input":"2023-11-20T16:04:39.303205Z","iopub.status.idle":"2023-11-20T16:04:39.31085Z","shell.execute_reply.started":"2023-11-20T16:04:39.303168Z","shell.execute_reply":"2023-11-20T16:04:39.309475Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Get the 3D values**","metadata":{"id":"FumEYoCPqXoN"}},{"cell_type":"code","source":"disp_resized = cv2.resize(depth, (1216, 352))\ndepth = 5.4 / disp_resized\ndepth = np.clip(depth, 0, 80)\n#depth = np.uint16(depth * 256)","metadata":{"execution":{"iopub.status.busy":"2023-11-20T16:08:50.025758Z","iopub.execute_input":"2023-11-20T16:08:50.026231Z","iopub.status.idle":"2023-11-20T16:08:50.035505Z","shell.execute_reply.started":"2023-11-20T16:08:50.026194Z","shell.execute_reply":"2023-11-20T16:08:50.033761Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(np.max(depth))","metadata":{"execution":{"iopub.status.busy":"2023-11-20T16:08:51.116242Z","iopub.execute_input":"2023-11-20T16:08:51.1169Z","iopub.status.idle":"2023-11-20T16:08:51.12256Z","shell.execute_reply.started":"2023-11-20T16:08:51.116865Z","shell.execute_reply":"2023-11-20T16:08:51.121379Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"height, width = depth.shape\nintrinsic = intrinsic_from_fov(height, width)\nprint(intrinsic)","metadata":{"execution":{"iopub.status.busy":"2023-11-20T16:08:53.361694Z","iopub.execute_input":"2023-11-20T16:08:53.362709Z","iopub.status.idle":"2023-11-20T16:08:53.369859Z","shell.execute_reply.started":"2023-11-20T16:08:53.36267Z","shell.execute_reply":"2023-11-20T16:08:53.368208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Real KITTI Values\n#K = [[721.5377   0.     609.5593]\n #[  0.     721.5377 172.854 ]\n #[  0.       0.       1.    ]]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cam_coords = np.zeros((height * width, 3))\n\nu0 = intrinsic[0, 2] \nv0 = intrinsic[1, 2] \nfx = intrinsic[0, 0] \nfy = intrinsic[1, 1]\ni = 0\n\n# Loop through each pixel in the image\nfor v in range(height):\n    for u in range(width):\n        x = (u - u0) * depth[v, u] / fx\n        y = (v - v0) * depth[v, u] / fy\n        z = depth[v, u]\n        cam_coords[i] = (x, y, z)\n        i += 1\ncam_coords = cam_coords.T","metadata":{"execution":{"iopub.status.busy":"2023-11-20T16:08:56.633952Z","iopub.execute_input":"2023-11-20T16:08:56.634759Z","iopub.status.idle":"2023-11-20T16:08:58.417361Z","shell.execute_reply.started":"2023-11-20T16:08:56.634718Z","shell.execute_reply":"2023-11-20T16:08:58.416015Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"project_depthmap(cam_coords, image, cam_pos=-2)","metadata":{"execution":{"iopub.status.busy":"2023-11-20T16:09:28.156437Z","iopub.execute_input":"2023-11-20T16:09:28.157636Z","iopub.status.idle":"2023-11-20T16:09:30.92191Z","shell.execute_reply.started":"2023-11-20T16:09:28.157577Z","shell.execute_reply":"2023-11-20T16:09:30.920602Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def project_topview(cam_points, rgb):\n    \"\"\"\n    Draw the topview projection\n    \"\"\"\n    max_longitudinal = 70\n    window_x = (-50, 50)\n    window_y = (-3, max_longitudinal)\n\n    x, y, z = cam_points\n    # flip the y-axis to positive upwards\n    y = - y\n\n    # We sample points for points less than 70m ahead and above ground\n    # Camera is mounted 1m above on an ego vehicle\n    ind = np.where((z < max_longitudinal) & (y > -1.2) & (y<2))\n    #ind = np.where(z < max_longitudinal)\n\n    bird_eye = cam_points[:3, ind]\n    colors_rgb = rgb[cam_points[1].astype(int), cam_points[0].astype(int), :]\n    filtered_colors = colors_rgb[ind[0]]/255.0\n\n    # Color by pixels or radial distance\n    fig, (ax0, ax1) = plt.subplots(1, 2, figsize=(24, 12))\n    ax0.imshow(rgb)\n    ax0.set_title(\"Original Image\")\n    ax0.axis(\"off\")\n    ax1.scatter(bird_eye[0, :], bird_eye[2, :], c=filtered_colors, s=0.1)\n    ax1.set_xlim(window_x)\n    ax1.set_ylim(window_y)\n    ax1.set_title('Bird Eye View')\n    plt.axis('off')\n\n    plt.gca().set_aspect('equal')\n    plt.show()\n\n\n# Do top view projection\nproject_topview(cam_coords, image)","metadata":{"id":"6sWnPlktetxI","execution":{"iopub.status.busy":"2023-11-20T16:10:49.093379Z","iopub.execute_input":"2023-11-20T16:10:49.093862Z","iopub.status.idle":"2023-11-20T16:10:50.22127Z","shell.execute_reply.started":"2023-11-20T16:10:49.093825Z","shell.execute_reply":"2023-11-20T16:10:50.220111Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}